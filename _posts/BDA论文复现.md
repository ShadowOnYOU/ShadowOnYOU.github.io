# BDA论文复现报告

## 1. 实验复现

代码顺利获取

环境变量配置较复杂，但也顺利完成

运行给指令定代码显示命令中部分参数未给出

修改给定指令代码后显示运行环境不达标，远不及其需要的运行环境

## 2. 论文内容

### 2.1 Abstract

此论文介绍了MEIM模型。模型旨在解决知识图谱嵌入中多分区嵌入相互作用（MEI）模型的一些缺点。

该模型通过引入独立的核张量用于集成效应和软正交性用语最大秩映射。

效果为提高了模型的表达能力，同时保持高效性。

### 2.2 Introduction

1. 知识图谱用于表示实体之间的关系信息。

2. 知识图谱的嵌入旨在预测知识图谱中实体之间的缺失关系。它们通常将三元组（h，t，r）表示为嵌入，并使用得分函数计算其匹配得分S(h，t，r)。得分函数定义了嵌入和交互模式之间的交互机制。

3. MEI模型

   1. 初始嵌入：我们为每个实体和关系初始化一个随机的嵌入向量。假设我们使用2维向量来表示实体和关系，初始嵌入可能如下所示：

      A: [0.2, 0.5]
      B: [0.7, 0.9]
      C: [0.3, 0.1]
      R1: [0.6, 0.4]
      R2: [0.8, 0.2]

   2. 局部交互计算：我们将嵌入向量划分为多个分区，每个分区负责处理嵌入向量的一部分。例如，我们将2维向量划分为两个1维分区。对于每个三元组，我们使用局部交互模式计算分区之间的交互得分。这些得分可以使用不同的方法计算，例如双线性映射。假设我们使用简单的内积作为交互得分计算方法。

      对于三元组 (A, R1, B)：

      - 分区1的交互得分：[0.2, 0.5] * [0.6, 0.4] = 0.2 * 0.6 + 0.5 * 0.4 = 0.32 + 0.2 = 0.52
      - 分区2的交互得分：[0.7, 0.9] * [0.6, 0.4] = 0.7 * 0.6 + 0.9 * 0.4 = 0.42 + 0.36 = 0.78
      - 完整的交互得分：[0.52, 0.78]

      对于三元组 (B, R2, C)：

      - 分区1的交互得分：[0.7, 0.9] * [0.8, 0.2] = 0.7 * 0.8 + 0.9 * 0.2 = 0.56 + 0.18 = 0.74
      - 分区2的交互得分：[0.3, 0.1] * [0.8, 0.2] = 0.3 * 0.8 + 0.1 * 0.2 = 0.24 + 0.02 = 0.26
      - 完整的交互得分：[0.74, 0.26]

   3. 预测缺失的关系：通过对缺失的关系进行类似的局部交互计算，我们可以预测实体之间的缺失关系。例如，如果我们要预测 (A, R2, C) 这个三元组，我们可以计算类似的局部交互得分。假设得分为 [0.5, 0.3]，我们可以根据得分来判断关系的存在概率。

4. MEI模型的两个缺点

   1. 使用一个核张量对所有分区进行局部交互会导致MEI中整体交互的相似性，可能损害集成效应。
   2. MEI中的关系映射矩阵是由相对较小的关系嵌入生成的，可能使模型容易退化。

5. MEIM（两个技术）

   1. 独立核张量改善集成效应
      1. 在MEIM模型中，每个分区都有一个独立的核张量。这意味着每个分区可以学习到不同的交互模式，而不受其他分区的影响。通过引入独立的核张量，MEIM模型能够增强整体交互的集成效应。每个分区的核张量可以根据本地交互模式进行自适应学习，从而提高模型的表达能力和预测性能。
   2. 通过软正交性改善模型表达能力的最大秩映射
      1. 软正交性和最大秩映射：MEIM模型通过软正交性技术改善模型的表达能力。软正交性是一种约束技术，它通过调整嵌入向量的表示方式，使得它们在嵌入空间中更接近正交。这种正交性约束可以帮助嵌入向量更好地捕捉实体和关系之间的语义关系。此外，MEIM模型还使用最大秩映射技术，它通过将嵌入向量映射到具有最大秩的低维子空间中，提高了模型的表达能力。这种映射可以减少嵌入向量之间的冗余信息，并更好地捕捉知识图谱的结构和语义。

### 2.3 Background

#### 2.3.1 Notations and Definitions

什么是上下文链接预测任务？

目标是在给定关系作为上下文的情况下，预测两个实体之间的连接或关系。这个任务通常在知识图谱上进行，知识图谱是一组表示实体之间关系的三元组（h，t，r）的集合。

在知识图谱中，每个三元组（h，t，r）由头实体（h）、尾实体（t）和关系（r）组成，它们分别属于实体集合E和关系集合R。

为了表示知识图谱，使用了一个三阶二进制数据张量G ∈ {0, 1} |E|×|E|×|R|。张量中的每个条目ghtr被设置为1，如果三元组（h，t，r）存在于知识图谱D中，则表示头实体h和尾实体t之间具有关系r的连接存在。

在任务中，模型以关系作为上下文，需要预测三元组中的缺失实例。简单说明就是三个变量，缺了一个。

#### 2.3.2 Tensor-Decomposition-based Knowledge Graph Embedding Models

此部分介绍了一些采用张量格式表示知识图谱数据张量，采用张量分解方法解决链接预测任务

1. RESCAL
   1. 这是一个早期模型，具有表达能力，但是映射矩阵随着嵌入维度的增长呈二次增长
2. DistMult
   1. 这是最简单的模型，使用稀疏对角映射矩阵
3. ComplEx

### 2.4 Multi-partition Embedding Interaction iMproved Beyond Block Term Format

提出了MEIM模型，它在基于张量分解的模型中引入了新的方面，利用了集成增强效应和最大秩关系映射，以及MEI所提供的多分区嵌入。

#### 2.4.1 评分函数

采用的是多分区嵌入表示，在局部交互中使用Tucker格式，在完全交互中使用块术语格式

![截屏2023-10-18 09.53.12](https://github.com/ShadowOnYOU/images/blob/main/test202310180953626.png?raw=true)

公式解析：

公式5展示了局部交互得分Sk(h, t, r; θ)的总和。

公式6展示了块术语格式。

公式8展示了带有块对角线映射矩阵的双线性格式，其中每个块MW,r,k由Wk×¯ 3rk:生成。公式8可以看作是一个动态线性神经网络，其中隐藏层MW,r,k由另一个超级神经网络[Ha et al., 2016]生成，其权重是核心张量Wk，输入为rk:。

#### 2.4.2 集成增强的核心张量

公式5中的评分函数可以看作是K个局部交互的集成系统，通过对它们的评分进行求和来工作。MEI模型简要的提到了这个视角，但是没有积极利用集成增强效应。MEI仅针对所有分区使用一个核心张量。MEI为所有分区学习了一种交互模式，类似于其他基于张量分解的模型（如ComplEx）。然而，这可能对集成系统的性能有害，因为局部交互模式相似而不是组合不同模式。要利用集成增强效应，重要的是促进局部交互之间的独立性和差异性。

##### 独立核心张量参数化

主要就是解决一个局部交互之间的独立性和差异性

1. 强制预测的评分不同。这个方法是一个过于强的约束，会带来更多的伤害
2. 明确强制不同的局部交互函数的不同参数。这种方法不能保证不同的交互。
3. 本文：不使用差异约束，而是使用独立性约束

![截屏2023-10-18 10.03.36](https://github.com/ShadowOnYOU/images/blob/main/test202310181003986.png?raw=true)

让模型自动从数据中学习独立的核心张量。使用独立的核心张量使模型能够学习独立且可能不同的局部交互，以改善集成增强效应。

但是，MEI在常见的深度学习框架中容易实现，只要使用矩阵乘积就可以。但独立核心张量使得MEIM中的多分区张量乘积难以搞笑实现。为了解决这个问题，作者选择将K个独立的核心张量堆叠在一起，形成了一个四阶张量。

#### 2.4.3 最大秩映射矩阵

MEI模型中，映射矩阵是上下文链接预测的关键。然而当矩阵的某些咧存在依赖关系时，它就变成了一个奇异矩阵。映射矩阵无法将实体的表示映射到整个预期的嵌入空间，而只能将其映射到一个维度较低的子空间中，从而降低了嵌入空间的有效大小。

为了解决这个问题，映射矩阵需要具有最大秩。

##### 通过软正交性实现最大秩映射矩阵

在实践中，强制严格正交可能是困难的或不必要的，因为主要目标是链接预测。相反，我们希望使映射矩阵尽可能接近正交矩阵的流形，同时不损害链接预测准确性。为了实现这一目标，通过拉格朗日松弛，将硬约束转化为软正交性损失项。

拉格朗日松弛

![截屏2023-10-18 10.29.55](https://github.com/ShadowOnYOU/images/blob/main/test202310181029340.png?raw=true)

为什么秩越大越好？

秩越大意味着映射矩阵具有更多的线性独立列向量。更多的列向量可以捕捉到更多的变化和关联性，从而增强了模型对于实体之间关系的表达能力。除此之外，较大的秩可以减少信息丢失，较小的秩对应的映射矩阵将实体的表示映射到一个纬度较低的子空间，容易导致部分信息的丢失。

为什么我们需要引入正交性？

1. 减少冗余信息：正交矩阵的列向量具有线性独立性，能捕捉到不同方向的变化。
2. 防止信息的丢失：正交矩阵保持了列向量的单位范数，不改变向量的长度。这确保了映射后的表示在长度上与原始向量相似，防止了信息丢失。
3. 改善泛化能力：正交性可以减少过拟合的风险，提高模型对未见样本的预测性能。
4. 减少参数量：正交矩阵具有较少的自由度，可以使用较少的参数量表示，减少了模型的复杂性。

#### 2.4.4 与之前模型的联系

MEIM && MEI

1. 效率与表达能力的权衡：MEIM与MEI一样，通过控制分块大小和学习交互模式，实现了效率和表达能力之间的系统权衡。通过调整参数数量和学习交互模式，可以灵活地平衡模型的效率和表达能力。
2. 计算成本：MEIM的参数数量与MEI相似，但在独立核张量方面采用了不同的参数化技术。然而，当处理大量实体和关系时，参数差异变得不那么重要。通过使用Einstein求和符号技术来实现独立核张量乘积，MEIM的计算速度与MEI相当。
3. 独立核张量：MEIM引入了独立核张量，可以学习独立的局部交互模式，从而改善集成效果。相比之下，MEI没有引入独立核张量这一机制。
4. 软正交性：MEIM引入了软正交性，通过平衡正交性和链接预测目标，学习到最大秩映射，提升了模型的表达能力。软正交性的使用可以避免严格正交性可能引发的问题，并且可以根据每个数据集选择如何平衡正交性和链接预测目标，这对于知识图谱嵌入任务至关重要。
5. MEIM的软正交性方法与这些模型不同。以前的模型追求严格正交性，而MEIM的目标是最大化映射矩阵的秩，因此使用软正交性作为手段来实现这一目标。软正交性允许根据特定数据集的情况平衡正交性和链接预测目标，这对于知识图谱嵌入至关重要。
6. MEIM的模型架构与以前的正交模型完全不同。在MEIM中，映射矩阵不是直接学习的，而是生成的。
7. MEIM是一个语义匹配模型，通过内积计算匹配分数，而其他正交模型是基于平移的模型，通过距离计算分数。

### 2.5 损失函数

最终的损失函数是链接预测损失和软正交性损失的总和：使用的损失函数包括链接预测损失和软正交性损失。链接预测损失衡量了模型在链接预测任务中的性能，通过计算预测分布与真实分布之间的交叉熵损失来衡量模型的预测准确性。软正交性损失是为了约束模型学习到的映射矩阵具有一定的正交性，从而提高模型在建模关系模式时的表达能力。

损失函数是干啥的？

是用于衡量模型的预测结果与真实值之间的差异或无擦好。在训练的过程中，模型的目标是通过最小化损失函数来调整参数，使得模型的预测结果与真实值尽可能接近。

### 2.6 实验

#### 2.6.1 实验设置

数据库：WN18RR，FB15K-237，YAGO3-10。数据集的内容包含了词汇信息、一般事实和维基百科中的一般事实。

评估方法：使用MRR（平均倒数排名）和H@k（前k个正确排名的三元组数量）来衡量性能。值越高，性能越好。为了避免在当前目标三元组之前对其他真实三元组进行排名时的惩罚，使用了过滤指标。

实践：MEIM模型是一个用于链接预测任务的神经网络模型，使用PyTorch实现。作者在不同的数据集的测试上使用了不同的K和C的值。除此之外，还使用了Droupout和批归一化技术。

对比基线：包括MEI和基于张量分析的模型

#### 2.6.2 参数效率

此部分即是MEIM与其他流行的基准模型进行了结果的比较。得出结论，MEIM明显优于其他的基准模型。

#### 2.6.3 主要的结果

MEIM在所有三个数据集上都取得了良好的成绩。从结果分析可知MEIM成功解决了MEI及其包含的机遇张量分解的模型的缺点，显著提高了所有数据集上的结果。

#### 2.6.4 分析与讨论

为什么这个模型可以给出如此良好的结果？

进行了消融研究和探讨了软正交性的效果。

消融研究：逐个移除模型的特征，观察每个特征对最终结果的贡献。结果显示，删除特征会降低结果，证实了它们的有效性。

软正交性：通过调整正交性参数的取值，观察结果的变化。他们发现强正交性对于某个数据集（WN18RR）表现良好，平均正交性对于另一个数据集（YAGO3-10）表现良好，而在第三个数据集（FB15K-237）上不需要正交性。这证明了MEIM的一个重要优势，即它的软正交性可以被调整以在每个数据集上实现最佳效果。

### 2.7 相关工作

1. 张量分解模型
2. 神经网络模型
3. 基于翻译的模型
4. 多种可以使用正交性的方法

### 2.8 总结

在这篇论文中，我们引入了一些新的方面来扩展基于张量分解的模型，利用集成增强效应和最大秩关系映射，除了MEI的多分区嵌入。我们提出了MEIM模型，其中包括两种新技术，即独立核心张量来改善集成效应，以及通过软正交性实现最大秩映射来提高表达能力。MEIM在链接预测方面取得了最先进的结果，包括使用相对较小的嵌入大小的庞大且困难的YAGO3-10数据集。此外，我们分析和展示了以前刚性正交性模型的局限性，并表明MEIM在多个数据集上使用软正交性效果良好。
