# 人机交互的第二篇论文

## 1. 摘要

系统ReadingQuizMaker旨在解决激励学生积极阅读的极限性，为教师提供一个方便的工具，用于设计高质量的问题，帮助学生理解阅读材料。

使用的是自然语言处理技术（NLP）来支持问题的创建过程

允许教师确定使用哪些NLP模型，选择模型的输入，并编辑生成的问题。灵活性使得教师在问题生成过程中具备了控制权，同时能利用NLP技术支持优势。

进行了一个对照实验，对照条件下教师被提供自动生成的问题进行编辑。结果显示，教师强烈偏好ReadingQuizMaker提供的人工智能协作方法，而不是完全自动化的方法。这凸显了在提供人工智能支持时，给用户控制权并提供AI结果的即时预览的重要性。

## 2. 介绍

背景：大学课程指定阅读材料是一个重要的部分。但是学生不完成阅读作业是高等教育中的一个普遍问题。只有20-30%的本科生阅读他们课堂上指定的材料。

如何更好的支持学生的学术阅读实践。

目前的工具：例如Perusalls用问题引导阅读

如何得到高质量的，发人深省的问题（在阅读过程中引导学生，帮助他们确定重要的内容，强调到课程结束时他们应该理解的内容，引发对内容中主要问题和印象的思考）需要大量的努力。

![截屏2023-10-28 09.50.56](https://github.com/ShadowOnYOU/images/blob/main/test202310280950239.png?raw=true)

户可以在Paper Panel上选择文本，并将其发送到Question Authoring Panel作为问题选项。ReadingQuizMaker提供了即时的AI建议预览，例如使用用户选择的文本进行实体替换和改写。在Question Authoring Panel上，用户会得到关于问题开头的建议，并可以使用自然语言处理工具包来改进问题选项，并通过否定模型生成干扰项。教师使用过的所有文本都会在Paper Panel上进行突出显示，并通过导航栏进行可视化，使用户可以检查内容覆盖范围。

**主要贡献**

1. 形成性研究：论文提供了一项形成性研究，揭示了教师在创建阅读测验问题时面临的挑战，并确定了开发能有效支持问题创建过程的工具的设计要求。
2. ReadingQuizMaker：论文介绍了ReadingQuizMaker，这是一个新颖的系统，旨在为教师在问题创建过程中提供基于自然语言处理的过程导向支持。该系统设计灵活，适应教师的自然工作流程，通过创新的交互设计加快问题创建速度，并提供AI建议以增强问题创建体验。
3. ReadingQuizMaker的评估：论文对ReadingQuizMaker进行了评估，展示了其可用性和实用性。研究结果显示了人工智能与教师联合合作的潜力，支持创造性教学设计工作。研究还强调了在提供AI支持时给用户控制权的重要性，以及通过立即预览AI结果来增加采纳的意义。

## 3. 相关工作

### 3.1 大学阅读作业的低遵从率

进行了一定的研究，只有20%到30%的本科生为课程做阅读准备。导致的主要原因之一就是缺乏动力。

原因：缺乏动力，低估阅读的重要性，阅读技能的不足（阅读作业和可视化图表的复杂性增加）

### 3.2 支持阅读实践的策略

1. 鼓励学生主动记录笔记
2. 社交批注工具，旨在在阅读过程中保持学生的积极注意力
3. 缺点：无法获得对内容理解的反馈

法2:阅读测验问题，但是如何设计好的问题十分困难

### 3.3 支持积极阅读的界面

在数字环境中模拟纸质阅读体验，重点是导航和做笔记。

Pearson等人开发了数字贴纸，可用作数字阅读的书签[66]。LiquidText引入了一个工作空间，供用户与他们的评论进行互动，支持理解公式符号和数学的功能。

### 3.4 面向教育目的的问题生成技术

法1:利用众包技术生成新的问题。例如，UpGrade根据先前学生的解决方案创建问题，而QMAps鼓励学生为彼此生成问题。

法2:开发端到端的自然语言处理模型来生成问题

笔者使用了人工智能与人类团队合作的方法。

### 3.5 教育中的人工智能系统

人工智能教育系统通常由人类教师引领教学决策过程，而人工智能则提供支持。

### 3.6 人工智能系统设计准则

ReadingQuizMaker的设计受到这些原则的启发，我们旨在检查用户如何与人工智能系统在一个依赖于专业知识的创造性和高风险任务上进行交互。

在设计人工智能系统时，需要在所有阶段都涉及从业人员，并进行迭代改进。Yang等人的研究表明，用户更喜欢高召回率的系统而不是高精确度的系统，这表明用户需要控制何时以及如何使用人工智能的结果。

## 4. 形成性研究

与11名大学教师合作，以了解他们手写问题的自然工作流程，目的是理解教师在创建问题时面临的独特挑战，并总结开发以用户为中心的系统的设计要求，以支持这个过程。

### 4.1 参与者和程序

自7所不同大学的11名教师参与了研究（6名男性，5名女性）。这些教师的教学经验范围从2年到40年不等，涵盖的学科包括计算机科学、信息科学、数据科学、教育、发展心理学和政治科学。

我们首先请参与者分享他们如何处理阅读任务。大部分时间用于让参与者根据他们选择的阅读文本设计问题。在整个过程中，没有提供任何支持。具体来说，我们要求他们设计问题（优先选择多项选择题），以帮助他们的学生理解和学习内容。我们要求参与者在整个过程中进行思考并表达出来。

然后，我们要求参与者思考他们是如何得出每个问题题干和选项的，并分享他们在整个过程中遇到的挑战。最后，研究人员要求参与者想象一个智能系统在测验设计过程中提供支持。具体而言，研究人员询问用户对与他们的问题创建过程相关的一系列自然语言处理任务的态度，例如，“如果系统可以为您改写这个句子，您觉得如何？”

### 4.2 结果

设计高质量的阅读问题是可取但难以实现的

希望使用阅读问题引导学生的思考。虽然一些教师还是喜欢使用阅读检验问题，但也强调问题应该以正确的方式设计

在测验题编写的过程中面临挑战。

如果自然语言处理支持良好、可控和透明可能会很有用

**设计要求**

- 支持教师创建有说服力的干扰项。许多参与者在生成干扰项方面表示困难，P4表示：“我希望干扰项对他们来说不容易猜到，但也不要太棘手。”大多数参与者表示，他们希望在创建有意义的干扰项方面得到支持。
- 提供过程导向的支持，使教师能够融入他们的专业知识。教师不喜欢传统的端到端人工智能方法来创建问题。教师希望在需要时能够灵活地做出决策并融入他们的专业知识，例如课程的背景、学生的背景知识等。
- 测验题目的创建需要快速并与教师当前的工作流程整合。大多数参与者希望缩短他们在创建问题上的时间。例如，P7和P9提到，他们希望尽可能少花时间编写问题，P10建议有一个系统来解决较低层次的问题，这对他们的工作流程有所帮助。
- 使教师能够轻松为问题编写反馈。反馈对教师来说非常重要，P5讨论了当他们注意到学生有误解时，他们通常会给学生一些评论。参与者表示，特别是对于错误答案，加入给予反馈的机制至关重要。
- 在与人工智能交互时给予教师一种控制感。当被问及是否愿意接受人工智能支持时，教师表示他们希望保持控制（P6）。P7评论说，如果人工智能提供建议，那么它会起作用，但他们更愿意保持控制并嵌入自己的知识来创建问题。这与人工智能与人类交互指南中的多个原则相一致，以支持有效的调用、撤销和更正。
- 在决策中给予教师灵活性。我们观察到不同的教师对创建问题有不同的策略。教师对不同的问题类型有偏好。例如，他们可以在大班课程中使用多项选择题，在研究生研讨课程中使用开放性问题。教师还希望问题库具有不同难度级别的题目。

## 5. ReadingQuizMaker的详细内容

旨在为教师提供创建与教育目标相一致的高质量阅读测验问题的过程支持。它适应教师自然的测验设计过程。该系统将阅读文本和问题创建面板并排显示，旨在缩短用户浏览文本所需的时间。

### 5.1 使用例子

Alice是一名大学教师，在课堂上指定一篇关于增强现实（AR）主题的论文作为必读材料。她希望创建阅读测验问题，引导学生阅读，并帮助他们理解论文的主要观点。Alice使用ReadingQuizMaker来创建问题。

Alice首先将论文的HTML文件加载到系统中。当她阅读摘要时，她有了一个问题的想法。她从菜单中选择一个问题开头，例如“以下关于论文的哪个陈述是不正确的？”然后，她在论文面板中寻找选项。ReadingQuizMaker提供了对所选句子进行改写的建议，Alice选择了一个她喜欢的改写版本。

在创建了几个正确选项后，Alice需要想出一个干扰项。她打开问题创作面板中的转换菜单，并尝试对一个选项进行否定。她对否定结果进行了些微修改，并完成了第一个问题。

随着Alice需要创建更多问题，她希望确保全面覆盖论文内容。她查看导航栏，该栏指示哪些部分的阅读需要更多关注。然后，Alice回顾她创建的所有问题并下载它们。

最后，Alice可以将问题导入类似Canvas的学习管理系统，并将测验作为课前阅读任务使用。

ReadingQuizMaker旨在简化创建阅读测验问题的过程，并为教师提供支持，从生成选项到检查内容覆盖范围。

### 5.2 详细设计

1. 使用HTML文件作为阅读来源，并支持几乎所有具有HTML版本的文章。并使用iframe显示文章的HTML文件，保留原始格式。
2. 导航栏支持用户查看内容覆盖范围，并导航到表格和图表。在形成性研究中，许多用户特别提到他们希望学生阅读表格和图表。
3. eadingQuizMaker提供即时的自然语言处理（NLP）建议预览。根据用户的文本选择，ReadingQuizMaker提供基于用户选择的NLP建议。用户在论文面板中阅读内容时，如果看到他们想在问题中使用的句子，可以选择该文本并将其转移到问题创作面板。系统提供两种选择文本的方式：1）通过鼠标拖选文本进行准确选择；2）在句子内双击进行整个句子的选择。用户选择文本后，系统会立即预览基于用户选择的NLP建议。具体而言，系统提供三种基于NLP的转换。当句子包含第一人称代词（如"我们"或"我们的设计"）时，使用正则表达式将其替换为"The authors"或"The design"。对于短句子，系统提供改写建议。对于较长的文本或段落，系统提供简明摘要。如果用户喜欢使用AI建议，他们可以将其转移到问题创作面板。用户也可以选择发送原始文本。当用户将文本发送为选项时，更多的AI建议将自动出现在添加的选项下方。用户可以决定是否使用这些建议。
4. ReadingQuizMaker的问题编写面板旨在与用户的自然工作流程相匹配，使用户能够顺利地创建问题。面板提供了三种类型的问题：多项选择题、多项回答题和开放性问题。用户可以从Paper Panel传输文本和图片，或者自由地添加内容。面板允许用户轻松地为问题选项添加反馈，并通过在Notes字段中添加注释来进行高级规划。
5. 为了帮助用户提出问题的问题干，ReadingQuizMaker提供了一个问题干库，该库是通过形成性研究众包得到的。问题干库包含28个问题模板，用户可以从中选择，或者自己输入新的问题干。系统还根据用户所在的部分（例如引言、相关工作）、问题类型（多项选择题、多项回答题、开放性问题）以及用户是否选择了一个图表来提供不同的问题干建议。用户还可以通过添加或删除“NOT”一词来否定一个问题干。
6. 审查和输出。在用户创建问题的过程中，他们可以像图7所示一样审查所有创建的问题。当用户拥有足够的问题后，他们可以将问题下载为一个.csv文件，该文件的格式已经准备好可以转换为.QTI包。QTI包中的测验与大多数学习管理系统（包括Canvas）兼容。用户可以轻松地将他们在ReadingQuizMaker中创建的问题导入到Canvas中。这也满足了形成性研究中揭示的教师希望有一个无缝的方法来节省时间的设计要求。

### NLP模型

使用哪些AI模型来辅助生成问题

1. 摘要生成：用于压缩长段落的内容
2. 释义：用于改写和简化橘子。帮助用户以保持原始意义的方式创造句子的替代版本
3. 否定：用于生成多想选择题的错误选项

### 系统迭代

进行了三轮试点测试，以交互式改进系统设计

1. 提高AI功能的可发现性。在试点研究中，我们发现用户倾向于不点击按钮来应用NLP转换。然而，当我们鼓励用户评估NLP建议时，他们发现这些建议是令人满意的。为了增加AI功能的可发现性，我们引入了NLP建议的即时预览，如图2所示。这避免了用户需要额外点击来获取支持，与人机交互指南[10]的要求一致，以支持高效的调用、撤销和更正。
2. 可视化NLP转换。我们发现参与者需要花时间比较NLP建议与原始文本。因此，我们在实体替换和否定转换之前后可视化了变化，如图2和图6所示。对于摘要生成和释义操作，我们没有实现可视化，因为它们是基于生成模型的，差异通常比几个词更明显。我们将将探索更好的可视化技术来帮助终端用户阅读和使用NLP结果留给未来的工作。
3. 引入阈值以提高NLP性能。在试点研究中，我们发现当用户将摘要操作应用于相对较短的文本时，效果不好。根据多次迭代，我们引入了一个400个字符的阈值来决定我们使用哪些模型给用户提供建议。如果用户选择的文本长度超过阈值，系统将给出摘要建议；否则，系统将给出释义建议，如图2所示。在NLP工具箱中，当选项长度低于阈值时，摘要操作将被禁用。

### 实现

ReadingQuizMaker是一个全栈Web应用程序，其中包含一个用于托管NLP模型的后端服务器。用户界面使用React.js和Django框架编写。Web应用程序连接到一个用Python实现的后端服务器，该服务器接受来自Web应用程序的API调用（例如，释义），应用NLP操作，并返回结果。Web应用程序通过DigitalOcean部署，后端服务器作为AWS EC2实例部署。

## 6. 评估研究

进行了经过IRB批准的评估研究

我们针对以下研究问题进行了探讨。

• RQ1：ReadingQuizMaker可用吗？教师能否使用ReadingQuizMaker创建满意的问题？

• RQ2：教师如何看待人工智能建议？它们的质量是否令人满意？它们是否会分散注意力？教师是否认为人工智能建议有用或令人不满意？

• RQ3：教师如何将ReadingQuizMaker提供的人工智能与自动生成问题方法进行比较？

• RQ4：用户遇到了哪些挑战，以及为开发面向教育的人工智能协作系统的设计有哪些启示？

### 参与者招募

我们通过社交媒体（包括教授的邮件列表和社交群体）和线下通信招募参与者。共有13位大学教师（9位男性，4位女性）来自10所大学参与了研究。所有参与者都教授或设计了需要阅读的大学课程，并设计了讨论或测验问题来帮助学生阅读。他们平均有4-5年的大学课程教学经验，最长的为17年。他们来自包括教育、信息科学、计算机科学、技术传播、工程教育和政治科学在内的学科。研究会议通过Zoom进行，每个会议持续90-100分钟。参与者获得了50美元的礼品卡作为补偿。在研究会议之前，我们要求参与者选择一篇他们想在会议中使用的阅读文本。唯一的要求是文本必须有在线HTML源。在13位参与者中，有7位使用了ACM数字图书馆的学术出版物，4位使用了在线教材章节，1位使用了在线教程，1位使用了新闻和观点网站上的新闻文章。

### 带有自动生成问题的基准条件

为了回答研究问题3，即教师如何看待ReadingQuizMaker提供的人工智能与自动生成问题方法的协作方法，我们引入了一个基准条件。我们开发了一个流程，从用户选择的阅读文本中自动生成多项选择题。在ReadingQuizMaker的试验测试中，我们观察到用户可能会从一个或相邻的段落中提取句子，将这些句子改写为正确选项，并将一个句子否定为错误选项。我们按照这个模式设计了自动生成问题的流程。

首先，我们使用BeautifulSoup [69]解析HTML文件，提取段落。然后，我们使用抽取式摘要模型提取关键句子。我们使用了BertSumExt [53]，它使用基于预训练BERT模型的文档级编码器。我们使用在CNN-DailyMail数据集[40]上训练的已发布检查点。我们使用该模型从每个段落中提取两个关键句子。然后，我们将两个相邻的段落组合起来生成一个问题的选项，这样每个问题涉及两个段落。我们将其中一个句子作为正确选项，将另一个句子改写为错误选项。

我们使用了自动问题生成的基准条件来与ReadingQuizMaker进行比较，以评估ReadingQuizMaker提供的人工智能建议的质量和实用性。

### 评估过程

首先向参与者介绍了ReadingQuizMaker的功能和用法。然后，我们要求他们选择一篇阅读文本，并使用ReadingQuizMaker创建问题。参与者使用ReadingQuizMaker创建问题的过程中，我们记录了他们的操作和想法。完成后，我们要求他们回答一些关于ReadingQuizMaker的使用体验和感受的问题。

接下来，我们介绍了自动生成问题的基准条件，并要求参与者使用该方法创建问题。他们在给定的时间内使用自动生成问题的方法创作尽可能多的问题。完成后，我们要求他们回答一些关于自动生成问题的体验和感受的问题。

在使用ReadingQuizMaker和自动生成问题的过程中，我们记录了参与者的操作和反馈。我们还记录了他们提出的问题的数量、质量和多样性。

### 数据分析方法

1. 系统日志分析
   1. 系统记录了每个自然语言处理（NLP）模型发送到后端的API调用日志。两名研究人员观看了用户研究录像，并对每个API调用进行标注，包括用户是否阅读或使用了建议，以及用户基于AI建议所做的修改。如果用户将AI建议作为选项发送到问题编写面板而不使用原始句子，则标记为采纳。如果用户在界面上停顿并阅读结果，则标记为阅读。由于有时参与者直接发送原始文本，而不等待AI建议显示，系统还记录了从立即预览功能采纳AI建议的情况，以及从NLP工具箱采纳AI建议的情况（需要显式点击）。
      类似地，我们还记录了用户采纳问题主干建议的情况。记录了用户是否查看过建议，以及是否采纳了建议以及对其进行了修改。如果用户向下滚动问题编写面板以查看更多选项，则标记为已查看。如果用户从菜单中选择了一个问题主干，则标记为采纳。用户手写的问题主干也被记录。
2. 自由谈思维记录的亲和图
   1. 研究录像被转录并使用亲和图进行分析。两位作者对转录进行解释，迭代地对解释笔记进行分组，并从数据中确定出现的主题。

## 7. 研究发现

### 7.1 RQ1:所有参与者成功使用RQM创建了他们满意的问题

教师对问题质量感到满意

问题创建被认为更容易和更快捷

几乎所有参与者都提到界面使用起来很容易

### 7.2 RQ2:ai的建议是有效的且可取的

用户采纳了60%的AI建议

教师们认为AI的建议是有用的且具有启发性的

教师们在AI建议不令人满意时进行进一步的修改。即便有时结果不如意，AI的建议也给予了他们灵感

在采纳的过程中，AI的可发现性时至关重要的。当AI建议能够轻松获得并且不需要用户额外操作时，用户更有可能查看和采纳这些建议。

### 7.3 RQ3:教师偏好RQM提供的人工智能与人类合作的方法

控制权很重要，参与者认为喜欢人工智能与人类合作的原因是觉得自己更有控制权

审查和编辑自动生成限制了教师的创造力

自动产生的问题质量较低。即便能够生成逻辑上合理的问题和选项，但是选项可能脱离上下文和教师的教育目标不一致

如果时间有限，自动生成的问题是可以接受的

### 7.4 RQ4:RQM中的用户挑战和经验以及设计影响

尽管参与者普遍认为ReadingQuizMaker系统易于使用，并有助于他们创建更高质量的问题，但他们在使用过程中报告了一些挑战。用户普遍发现生成干扰选项具有挑战性。

对系统设计的影响：探索更多的方法和技术为了帮助用户生成干扰选项；扩大问题引导语库的范围，以覆盖更多领域和主题，使其对不同类型的内容都能提供有用的建议；考虑提供一些问题引导语的定制选项。

## 8. 案例的使用演示

两个场景：

7.1 通过现有的学习管理平台用作形成性或总结性评估

在ReadingQuizMaker中创建的问题可以下载为.csv文件，并转换为.QTI包，可以直接导入到现有的学习管理系统（如Canvas）中。这使得教师可以将他们在系统中创建的问题分配给学生，作为形成性或总结性评估。

7.2 用作学生的阅读指南

在ReadingQuizMaker中创建的问题也可以制作成交互式的阅读指南。学生可以通过扩展的ReadingQuizMaker界面回答生成的问题。如果他们答错了问题，界面将给予他们反馈，突出显示内容在阅读中的位置，这在问题创建过程中已经记录下来了。

## 9. 讨论

此部分讨论潜在的未来发展方向

8.1 增加AI输出的发现性、可视化和可解释性

在研究中，我们发现当AI建议易于获取并且不需要额外的操作时，用户更有可能检查和采纳AI建议。例如，当用户选择一个句子后，系统会自动显示改写建议，而改写建议相对于摘要和否定操作更容易被检查和采纳。这与人工智能与人类交互的准则相一致，支持高效地调用、拒绝和修正人工智能结果。此外，我们发现一些用户很难解读自然语言处理结果，特别是对于摘要而言。用户需要阅读原始段落并阅读摘要以确保准确性。在ReadingQuizMaker中，我们实施了可视化来突出实体替换和否定的变化。然而，我们没有为摘要和改写模型提供可视化，因为其中一些涉及到了巨大的变化。未来的工作需要研究更好的可视化技术，帮助用户更有效地理解自然语言处理结果。最后，一些用户很难理解模型是如何生成结果的，尤其是对于否定模型而言。一些用户想知道为什么模型选择了某个词进行否定，而其他用户更喜欢我们提供的用户可控版本的否定模型。未来的工作需要探索向最终用户解释生成模型的技术，并为用户控制自然语言处理模型提供方法。

8.2 支持教育内容创建的人工智能与人类合作方法

我们的研究加入了以前的工作，展示了人工智能与人类合作支持教育的力量。我们发现在问题创建方面，用户更偏好于ReadingQuizMaker提供的人工智能与人类合作方法，而不是自动化方法。在ReadingQuizMaker中，用户对整个过程拥有完全控制权。这不仅给用户一种安全感，也使得过程对他们来说更加流畅。一些用户表示他们希望能够跟踪整个过程，例如记录使用了哪些文本，每个选项来自阅读的哪个部分等。另一方面，用户认为自动生成的问题质量较低。其中一个原因是人工智能很难确定重点，即对哪些重要内容创建问题。当用于人工智能模型的输入与用户的期望不一致时，改写或否定的句子会失去上下文，作为问题选项的满意度会降低。自动化方法可能会生成逻辑上正确的多项选择题，但教师们发现选项与上下文无关且毫无意义。我们认为，在需要专业知识和创造力的教育内容创作中，人类参与指定AI系统的输入是必要的，并有助于改进对AI建议的采纳。随着ChatGPT等大型语言模型的普及以及研究人员探索使用语言模型来实现教育目标，我们的研究结果提供了重要的建议，即在教育内容创建这样的高风险任务中，允许用户提供输入并在过程中给予用户充分的控制权比完全自动化的方法更可取。

另一个方向是使用可控的AI模型，用户可以指定额外的参数。我们为否定模型实现了一个简单的可控版本，结果是可以接受的。然而，有时候否定的结果并不令人满意。例如，用户可能选择否定一个特定的词，而模型选择了相邻的词进行否定。未来的工作需要开发和整合可控的自然语言处理模型，并帮助用户指定参数，获得符合他们目标的结果。对于教育内容创建来说，包括否定和改写模型的“关注”词可以减少丢失重要信息的风险，并生成符合用户期望的结果。

8.3 改进问题创建系统的启示

创建问题的最大挑战之一是知道要问什么。一些参与者发现ReadingQuizMaker提供的摘要能够激发灵感并给他们提供思路，但是知道要摘要什么以及如何将摘要结果转化为问题仍然具有挑战性。未来的工作可以探索帮助人们识别问题机会的方法。许多用户发现很难想出好的干扰项。尽管许多参与者使用否定来生成干扰项，但是想出一个合理的错误选项仍然具有挑战性。根据人们展示的策略，我们建议未来的工作探索从文本的特定位置提取信息，例如相关工作部分，以生成干扰项。在当前版本的ReadingQuizMaker中，问题引导语主要设计用于学术论文，并不适用于其他阅读文本，如教程和教科书。随着ReadingQuizMaker的用户增加和多样化，众包的问题库将增长，并在未来为用户提供更多多样化的建议。在ReadingQuizMaker中，用户需要等待2-3秒钟才能加载AI建议。在评估研究中，我们没有观察到用户对延迟感到烦恼或分心，因为他们通常会花时间阅读原始文本。将大型语言模型整合到用户界面中的未来工作需要减少延迟并研究对用户体验的潜在影响。

## 10 && 11. 局限 && 结论

局限：

参与者样本少；我们要求用户自我报告该方法是否节省了他们在创建问题上的时间，实际应担需要进行更全面的定量研究来分析因素；工作集中在面向教师的评估研究，需要进行大规模面向学生的试验，以了解生成的问题是否有助于学生的阅读理解和学习

结论：

我们提出了ReadingQuizMaker，它支持教师方便地设计高质量的问题，帮助学生理解阅读材料。ReadingQuizMaker适应教师自然的问题创建工作流程，同时提供基于自然语言处理的过程支持。ReadingQuizMaker使教师能够决定何时以及使用哪些自然语言处理模型，选择模型的输入，并编辑模型的输出。在评估研究中，教师发现生成的问题与他们以前设计的测验相当。教师赞赏ReadingQuizMaker的易用性，并认为自然语言处理的建议令人满意且有帮助。我们将ReadingQuizMaker与基线条件进行了比较，基线条件下教师被提供自动生成的问题进行编辑。教师对ReadingQuizMaker提供的人工智能与人类合作方法表现出强烈的偏好。与ReadingQuizMaker相比，教师认为自动生成的问题质量较低，问题中的内容与上下文无关且毫无意义。我们的研究结果为利用大型语言模型支持教育提供了重要建议。我们认为，在教育内容创建等高风险任务中，允许用户提供输入并在过程中给予用户充分的控制权比完全自动化的方法更可取。





